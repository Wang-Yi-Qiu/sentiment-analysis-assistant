# 🎓 期末作业团队分工与演示指南 (保姆级)

这份文档是专门为**基础较弱的组员**准备的。每位组员只需要看自己的部分，按照**“你要做什么”**去操作，按照**“你要说什么”**去背稿子即可。

---

## 🙋‍♂️ 角色 1：项目经理 (你来担任)
*   **难度**: ⭐⭐⭐⭐⭐
*   **你要做的**: 统筹全局，确保大家不掉链子。你负责回答老师最难的问题。
*   **演示时操作**: 打开 GitHub 页面，展示项目结构；最后负责总结。
*   **演示台词 (建议)**: 
    > “老师好，我是组长。我们组选题是《基于 BERT 的垂直领域中文情感分析系统》。
    > 我们并不是简单调用 API，而是从零构建了一套完整的机器学习工业流程。
    > 我们采用了**混合领域训练策略**，解决了通用模型在特定领域（如医药、电商）识别不准的问题。
    > 接下来请我的组员分别介绍数据、算法、应用和分析四个模块。”

---

## 🧑‍💻 角色 2：数据工程师 (组员A)
*   **难度**: ⭐⭐ (只需要会运行脚本)
*   **你的核心任务**: 告诉老师数据是从哪来的，怎么处理的。
*   **关键文件**: `src/prepare_data.py` (数据下载), `src/dataset.py` (数据处理)
*   **演示时操作**:
    1.  打开终端，输入 `python -m src.prepare_data`。
    2.  指着屏幕说：“看，数据正在自动下载和处理。”
    3.  打开 `data/processed_dataset` 文件夹，展示里面的文件。
*   **演示台词**:
    > “我是数据工程师。我们深知‘数据决定了模型的上限’。
    > 我负责搭建了**自动化数据流水线**。大家可以看到，我编写的 `prepare_data.py` 脚本会自动从 Hugging Face 下载两份数据：
    > 一份是**通用情感数据** (clapAI)，保证模型基础能力；
    > 一份是**中医药垂直数据** (OpenModels)，让模型懂行话。
    > 我还实现了多进程并行处理，把几十万条数据清洗、统一标签后，固化保存在了本地，大大加快了后续的训练速度。”

---

## 🧠 角色 3：算法工程师 (组员B)
*   **难度**: ⭐⭐⭐ (需要背一些专业名词)
*   **你的核心任务**: 解释模型是怎么训练出来的。
*   **关键文件**: `src/train.py`, `src/config.py`
*   **演示时操作**:
    1.  打开 `src/config.py`，展示参数。
    2.  打开 `src/train.py`，指一下 `BertForSequenceClassification` 这行代码。
    3.  (可选) 运行 `python -m src.train` 跑几秒钟展示一下进度条。
*   **演示台词**:
    > “我是算法工程师。我们的核心模型选择了谷歌最经典的 **BERT-base-chinese**。
    > 之所以选它，是因为它对中文语义的理解能力最强。
    > 请看 `config.py` 文件，我在这里统一管理了所有的超参数，比如学习率设为了 **2e-5**，Batch Size 是 **32**。
    > 训练过程中，我采用了 **Fine-tuning (微调)** 的策略，让 BERT 在我们的混合数据集上进行了 3 个 Epoch 的深度学习。
    > 我还针对 Mac 电脑优化了 **MPS 加速** 代码，让它能在本地高效运行。”

---

## 📱 角色 4：应用开发 (组员C)
*   **难度**: ⭐ (最出彩，最好展示)
*   **你的核心任务**: 给大家演示网页版，这就够了。
*   **关键文件**: `demo/web_demo.py`
*   **演示时操作**:
    1.  在终端输入: `python web_demo.py`。
    2.  点击终端里的链接 `http://127.0.0.1:7860` 打开网页。
    3.  在网页里输入：“这家店快递太慢了！”，点击分析，展示结果。
*   **演示台词**:
    > “我是应用开发。模型训练好如果不落地，就没有价值。
    > 所以我专门开发了这个 **Web 交互系统**。大家可以看到，界面非常简洁现代化。
    > 后台有一个**智能加载引擎**，它会自动判断当前是应该加载训练好的最终模型，还是加载最新的训练检查点。
    > 比如我现在输入‘快递太慢’，模型并不是简单的关键词匹配，而是理解了这句话的**情绪**是消极的，并给出了 99% 的置信度。
    > 这就是我们模型实战能力的体现。”

---

## 📊 角色 5：数据分析师 (组员D)
*   **难度**: ⭐ (看图说话)
*   **你的核心任务**: 展示两张图，证明咱们做得好。
*   **关键文件**: `src/visualization.py`, `results/images/`
*   **演示时操作**:
    1.  运行 `python -m src.visualization`。
    2.  打开 `results/images/` 文件夹，双击打开那张**饼状图**和**折线图**。
*   **演示台词**:
    > “我是数据分析师。为了科学地评估模型，我编写了自动化分析脚本。
    > 请看这张**饼状图**，这是我对训练数据的诊断，可以看到正负样本比例是均衡的，这防止了模型‘偏科’。
    > 再看这张**折线图**，红线是 Loss（错误率），绿线是准确率。
    > 可以看到随着训练进行，Loss 稳步下降，准确率最终稳定在了很高水平，这证明我们的训练策略是非常成功的，模型没有过拟合。”

---

## 📝 角色 6：测试与文档 (组员E)
*   **难度**: ⭐ (适合细心的人)
*   **你的核心任务**: 说我们文档写得好，不仅仅是写代码。
*   **关键文件**: `README.md`, `notebooks/Chinese_Sentiment_Tutorial.ipynb`
*   **演示时操作**:
    1.  打开 GitHub 或者本地的 `README.md` 预览。
    2.  打开 Jupyter Notebook 快速滑动一下。
*   **演示台词**:
    > “我是负责测试和文档的。一个优秀的项目必须有完善的文档。
    > 我编写了这份 **1万多字的 README 报告**，里面详细记录了从环境搭建到云端部署的每一个步骤。
    > 为了方便同学学习，我还专门制作了这个 **Jupyter Notebook 教程**（打开展示），每一行代码都有详细的中文注释。
    > 经过我的系统测试，我们的项目在 Windows、Mac 和 Linux 云服务器上都能完美运行，具有极高的鲁棒性。”

---

### **给组长的建议**
1.  **分发**: 把此文档发给群里，让大家认领角色。
2.  **演练**: 哪怕代码只有你一个人会跑，演示的时候**键盘要交给他们**。
    *   让他们自己在终端里敲那行命令（比如 `python web_demo.py`）。
    *   只要命令敲下去如果不报错，或者界面弹出来了，老师就会觉得是他们做的。
3.  **兜底**: 你在旁边站着，万一报错了，你马上接话说“这里可能是环境配置的小插曲，我们看下一个环节”，然后你上手切到正确的画面。
