{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸŽ“ ä¸­æ–‡æƒ…æ„Ÿåˆ†æžç³»ç»Ÿï¼šäº¤äº’å¼æ•™å­¦æ•™ç¨‹\n",
                "\n",
                "## ðŸ‘‹ æ¬¢è¿Žï¼\n",
                "æ¬¢è¿Žæ¥åˆ°è¿™ä»½ä¸“ä¸ºå­¦ä¹ è€…è®¾è®¡çš„ **äº¤äº’å¼ Jupyter Notebook** æ•™ç¨‹ã€‚\n",
                "\n",
                "**æœ¬é¡¹ç›®çš„ç›®æ ‡**ï¼šæˆ‘ä»¬å°†ä»Žé›¶å¼€å§‹ï¼Œæž„å»ºä¸€ä¸ªèƒ½å¤Ÿç†è§£ä¸­æ–‡è¯„è®ºâ€œæƒ…ç»ªâ€çš„äººå·¥æ™ºèƒ½æ¨¡åž‹ã€‚ä¸æ˜¯ç®€å•åœ°è°ƒç”¨ APIï¼Œè€Œæ˜¯äº²æ‰‹è®­ç»ƒä¸€ä¸ªå·¥ä¸šçº§çš„ **BERT** æ¨¡åž‹ã€‚\n",
                "\n",
                "## ðŸ“š ä½ å°†å­¦åˆ°ä»€ä¹ˆï¼Ÿ\n",
                "1.  **çŽ¯å¢ƒé…ç½®**ï¼šå¦‚ä½•åˆ©ç”¨ Mac çš„ MPS åŠ é€Ÿæ·±åº¦å­¦ä¹ ã€‚\n",
                "2.  **æ•°æ®å·¥ç¨‹**ï¼šä»Ž Hugging Face èŽ·å–æ•°æ®ï¼Œå¹¶æ¸…æ´—ã€ç»Ÿä¸€ã€‚\n",
                "3.  **æ¨¡åž‹åŽŸç†**ï¼šBERT æ˜¯å¦‚ä½•ç†è§£ä¸­æ–‡çš„ï¼Ÿ\n",
                "4.  **æ¨¡åž‹è®­ç»ƒ**ï¼šå¦‚ä½•è¿›è¡Œå¾®è°ƒ (Fine-tuning) ä»¥é€‚åº”ç‰¹å®šä»»åŠ¡ã€‚\n",
                "5.  **æ¨¡åž‹åº”ç”¨**ï¼šå¦‚ä½•ç”¨è‡ªå·±è®­ç»ƒçš„æ¨¡åž‹æ¥åˆ†æžä¸€å¥è¯ã€‚\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1ï¸âƒ£ ç¬¬ä¸€æ­¥ï¼šå¯¼å…¥å·¥å…·åŒ…ä¸ŽçŽ¯å¢ƒæ£€æŸ¥\n",
                "\n",
                "åœ¨å¼€å§‹åšèœä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å…ˆæŠŠé”…ç¢—ç“¢ç›†ï¼ˆå·¥å…·åŒ…ï¼‰å‡†å¤‡å¥½ã€‚\n",
                "\n",
                "**æ ¸å¿ƒå·¥å…·ä»‹ç»**ï¼š\n",
                "*   **Transformers**: ç”± Hugging Face æä¾›ï¼Œæ˜¯ç›®å‰å…¨ä¸–ç•Œæœ€æµè¡Œçš„ NLP åº“ï¼Œç”¨æ¥åŠ è½½ BERT æ¨¡åž‹ã€‚\n",
                "*   **Datasets**:è¿™ä¹Ÿæ˜¯ Hugging Face çš„äº§å“ï¼Œç”¨æ¥ä¸‹è½½ä¸Žå¤„ç†æµ·é‡æ•°æ®ã€‚\n",
                "*   **Pandas**: ç”¨æ¥åƒ Excel ä¸€æ ·æŸ¥çœ‹æ•°æ®è¡¨æ ¼ã€‚\n",
                "*   **Torch**: Pytorch æ·±åº¦å­¦ä¹ æ¡†æž¶ï¼Œæˆ‘ä»¬çš„â€œå¼•æ“Žâ€ã€‚"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import torch\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from datasets import load_dataset, concatenate_datasets\n",
                "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
                "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
                "\n",
                "# === ç¡¬ä»¶åŠ é€Ÿæ£€æŸ¥ ===\n",
                "# æ·±åº¦å­¦ä¹ éœ€è¦å¤§é‡çš„çŸ©é˜µè®¡ç®—ï¼ŒCPU ç®—å¾—å¤ªæ…¢ã€‚\n",
                "# Mac ç”µè„‘æœ‰ä¸“é—¨çš„ MPS (Metal Performance Shaders) åŠ é€ŸèŠ¯ç‰‡ã€‚\n",
                "if torch.backends.mps.is_available():\n",
                "    device = torch.device(\"mps\")\n",
                "    print(\"âœ… æ­å–œï¼æ£€æµ‹åˆ° Mac MPS ç¡¬ä»¶åŠ é€Ÿï¼Œè®­ç»ƒé€Ÿåº¦å°†èµ·é£žï¼ðŸš€\")\n",
                "elif torch.cuda.is_available():\n",
                "    device = torch.device(\"cuda\")\n",
                "    print(\"âœ… æ£€æµ‹åˆ° NVIDIA CUDAï¼Œå°†ä½¿ç”¨ GPU è®­ç»ƒã€‚\")\n",
                "else:\n",
                "    device = torch.device(\"cpu\")\n",
                "    print(\"âš ï¸ æœªæ£€æµ‹åˆ° GPUï¼Œå°†ä½¿ç”¨ CPU è®­ç»ƒã€‚é€Ÿåº¦å¯èƒ½ä¼šæ¯”è¾ƒæ…¢ï¼Œè¯·è€å¿ƒç­‰å¾…ã€‚â˜•ï¸\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2ï¸âƒ£ ç¬¬äºŒæ­¥ï¼šé…ç½®å‚æ•° (Config)\n",
                "\n",
                "ä¸ºäº†è®©ä»£ç æ•´æ´ï¼Œæˆ‘ä»¬å°†æ‰€æœ‰çš„â€œè®¾ç½®é¡¹â€éƒ½æ”¾åœ¨è¿™é‡Œã€‚è¿™å°±å¥½æ¯”åšèœå‰çš„â€œèœè°±â€ã€‚\n",
                "\n",
                "*   **BASE_MODEL**: æˆ‘ä»¬é€‰ç”¨çš„åŸºåº•æ¨¡åž‹æ˜¯ `bert-base-chinese`ï¼Œå®ƒæ˜¯è°·æ­Œè®­ç»ƒå¥½çš„ã€å·²ç»è¯»è¿‡å‡ äº¿å­—ä¸­æ–‡çš„â€œé«˜æç”Ÿâ€ã€‚\n",
                "*   **NUM_EPOCHS**: è®­ç»ƒè½®æ•°ã€‚è®¾ä¸º 3ï¼Œæ„å‘³ç€æ¨¡åž‹ä¼šæŠŠæˆ‘ä»¬çš„æ•™æä»Žå¤´åˆ°å°¾çœ‹ 3 éã€‚"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class Config:\n",
                "    # åŸºæ¨¡åž‹ï¼šBERT ä¸­æ–‡ç‰ˆ\n",
                "    BASE_MODEL = \"google-bert/bert-base-chinese\"\n",
                "    \n",
                "    # åˆ†ç±»æ•°é‡ï¼š3ç±» (æ¶ˆæž-0, ä¸­æ€§-1, ç§¯æž-2)\n",
                "    NUM_LABELS = 3\n",
                "    \n",
                "    # æ¯ä¸€å¥è¯æœ€é•¿å¤„ç†å¤šå°‘ä¸ªå­—ï¼Ÿè¶…è¿‡çš„æˆªæ–­ï¼Œä¸è¶³çš„è¡¥0\n",
                "    MAX_LENGTH = 128\n",
                "    \n",
                "    # è·¯å¾„é…ç½®\n",
                "    OUTPUT_DIR = \"../checkpoints/tutorial_model\"\n",
                "    \n",
                "    # è®­ç»ƒè¶…å‚æ•°\n",
                "    BATCH_SIZE = 16  # ä¸€æ¬¡å¯ä»¥å¹¶è¡Œå¤„ç†å¤šå°‘å¥è¯ (çœ‹æ˜¾å­˜å¤§å°)\n",
                "    LEARNING_RATE = 2e-5  # å­¦ä¹ çŽ‡ï¼šæ¨¡åž‹å­¦å¾—å¤ªå¿«å®¹æ˜“å­¦åï¼Œå¤ªæ…¢å®¹æ˜“å­¦ä¸ä¼šã€‚2e-5 æ˜¯ç»éªŒå€¼ã€‚\n",
                "    NUM_EPOCHS = 3   # è®­ç»ƒå‡ è½®\n",
                "    \n",
                "    # æ ‡ç­¾å­—å…¸\n",
                "    ID2LABEL = {0: 'Negative (æ¶ˆæž)', 1: 'Neutral (ä¸­æ€§)', 2: 'Positive (ç§¯æž)'}\n",
                "    LABEL2ID = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
                "\n",
                "print(\"é…ç½®åŠ è½½å®Œæ¯•ã€‚\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3ï¸âƒ£ ç¬¬ä¸‰æ­¥ï¼šå‡†å¤‡æ•°æ® (Data Preparation)\n",
                "\n",
                "æˆ‘ä»¬çš„ç­–ç•¥æ˜¯ **â€œæ··åˆåŒæ‰“â€**ï¼š\n",
                "1.  **é€šç”¨æ•°æ®** (`clapAI`): åŒ…å«æ—¥å¸¸ç”Ÿæ´»çš„å„ç§è¯„è®ºï¼Œè®©æ¨¡åž‹æ‡‚å¸¸è¯†ã€‚\n",
                "2.  **åž‚ç›´æ•°æ®** (`OpenModels`): åŒ…å«ä¸­åŒ»è¯é¢†åŸŸçš„è¯„è®ºï¼Œè®©æ¨¡åž‹æ‡‚è¡Œè¯ã€‚\n",
                "\n",
                "ä¸‹é¢çš„ä»£ç ä¼šè‡ªåŠ¨ä»Žç½‘ç»œåŠ è½½è¿™äº›æ•°æ®ï¼Œå¹¶è¿›è¡Œæ¸…æ´—ã€‚"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# åŠ è½½ Tokenizer (åˆ†è¯å™¨)\n",
                "# å®ƒçš„ä½œç”¨æ˜¯æŠŠæ±‰å­—è½¬æ¢æˆæ¨¡åž‹èƒ½è¯»æ‡‚çš„æ•°å­— ID\n",
                "tokenizer = AutoTokenizer.from_pretrained(Config.BASE_MODEL)\n",
                "\n",
                "def prepare_dataset():\n",
                "    print(\"â³ æ­£åœ¨åŠ è½½æ•°æ® (å¯èƒ½éœ€è¦ä¸€ç‚¹æ—¶é—´ä¸‹è½½)...\")\n",
                "    \n",
                "    # ä¸ºäº†æ¼”ç¤ºé€Ÿåº¦ï¼Œæˆ‘ä»¬åªå–å‰ 1000 æ¡æ•°æ® (æ­£å¼è®­ç»ƒæ—¶ä¼šç”¨å…¨éƒ¨æ•°æ®)\n",
                "    # å¦‚æžœç”µè„‘æ€§èƒ½å¥½ï¼Œå¯ä»¥æŠŠ split=\"train[:1000]\" æ”¹æˆ split=\"train\"\n",
                "    sample_size = 500\n",
                "    \n",
                "    # 1. åŠ è½½é€šç”¨æƒ…æ„Ÿæ•°æ®\n",
                "    ds_clap = load_dataset(\"clapAI/MultiLingualSentiment\", split=f\"train[:{sample_size}]\", trust_remote_code=True)\n",
                "    ds_clap = ds_clap.filter(lambda x: x['language'] == 'zh') # åªç•™ä¸­æ–‡\n",
                "    \n",
                "    # 2. åŠ è½½ä¸­åŒ»è¯æƒ…æ„Ÿæ•°æ®\n",
                "    ds_med = load_dataset(\"OpenModels/Chinese-Herbal-Medicine-Sentiment\", split=f\"train[:{sample_size}]\", trust_remote_code=True)\n",
                "    \n",
                "    # 3. ç»Ÿä¸€åˆ—å\n",
                "    # ä¸åŒæ•°æ®é›†çš„åˆ—åå¯èƒ½ä¸ä¸€æ ·ï¼Œæˆ‘ä»¬è¦æŠŠå®ƒä»¬ç»Ÿä¸€æ”¹æˆ 'text' å’Œ 'label'\n",
                "    if 'review_text' in ds_med.column_names: ds_med = ds_med.rename_column('review_text', 'text')\n",
                "    if 'sentiment_label' in ds_med.column_names: ds_med = ds_med.rename_column('sentiment_label', 'label')\n",
                "    \n",
                "    # 4. åˆå¹¶æ•°æ®é›†\n",
                "    common_cols = ['text', 'label']\n",
                "    combined = concatenate_datasets([ds_clap.select_columns(common_cols), ds_med.select_columns(common_cols)])\n",
                "    \n",
                "    # 5. æ•°æ®æ¸…æ´—ä¸Žç»Ÿä¸€æ ‡ç­¾\n",
                "    def process_data(example):\n",
                "        # ç»Ÿä¸€æ ‡ç­¾ä¸ºæ•°å­— 0, 1, 2\n",
                "        lbl = example['label']\n",
                "        if isinstance(lbl, str):\n",
                "            lbl = lbl.lower()\n",
                "            if lbl in ['negative', '0']: lbl = 0\n",
                "            elif lbl in ['neutral', '1']: lbl = 1\n",
                "            elif lbl in ['positive', '2']: lbl = 2\n",
                "        return {'labels': int(lbl)}\n",
                "        \n",
                "    combined = combined.map(process_data)\n",
                "    \n",
                "    # 6. åˆ†è¯ (Tokenization)\n",
                "    def tokenize(batch):\n",
                "        return tokenizer(batch['text'], padding=\"max_length\", truncation=True, max_length=Config.MAX_LENGTH)\n",
                "        \n",
                "    print(\"âœ‚ï¸ æ­£åœ¨è¿›è¡Œåˆ†è¯å¤„ç†...\")\n",
                "    tokenized_ds = combined.map(tokenize, batched=True)\n",
                "    \n",
                "    # 7. åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›† (90% è®­ç»ƒ, 10% éªŒè¯)\n",
                "    return tokenized_ds.train_test_split(test_size=0.1)\n",
                "\n",
                "# æ‰§è¡Œæ•°æ®å‡†å¤‡\n",
                "dataset = prepare_dataset()\n",
                "print(f\"\\nâœ… æ•°æ®å‡†å¤‡å®Œæˆï¼\\nè®­ç»ƒé›†å¤§å°: {len(dataset['train'])} æ¡\\næµ‹è¯•é›†å¤§å°: {len(dataset['test'])} æ¡\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4ï¸âƒ£ ç¬¬å››æ­¥ï¼šæ•°æ®å¯è§†åŒ– (Data Visualization)\n",
                "\n",
                "å¾ˆå¤šæ—¶å€™æ¨¡åž‹è®­ç»ƒä¸å¥½æ˜¯å› ä¸ºæ•°æ®åˆ†å¸ƒä¸å‡åŒ€ï¼ˆæ¯”å¦‚å…¨æ˜¯å¥½è¯„ï¼Œé‚£æ¨¡åž‹åªè¦ä¸€ç›´çŒœå¥½è¯„å‡†ç¡®çŽ‡ä¹Ÿå¾ˆé«˜ï¼Œä½†è¿™æ²¡ç”¨ï¼‰ã€‚\n",
                "è®©æˆ‘ä»¬ç”»ä¸ªé¥¼å›¾æ¥çœ‹çœ‹æˆ‘ä»¬çš„æ•°æ®æ€Žä¹ˆæ ·ã€‚"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ä»Ž dataset ä¸­æå– label åˆ—\n",
                "train_labels = dataset['train']['labels']\n",
                "\n",
                "# ç»Ÿè®¡æ¯ä¸ªç±»åˆ«çš„æ•°é‡\n",
                "labels_count = pd.Series(train_labels).value_counts().sort_index()\n",
                "labels_name = [Config.ID2LABEL[i] for i in labels_count.index]\n",
                "\n",
                "# ç”±äºŽ Matplotlib é»˜è®¤ä¸æ”¯æŒä¸­æ–‡ï¼Œæˆ‘ä»¬ç”¨è‹±æ–‡æ˜¾ç¤ºæˆ–è€…è®¾ç½®å­—ä½“ï¼Œè¿™é‡Œä¸ºäº†ç®€å•ç›´æŽ¥ç”¨è‹±æ–‡\n",
                "plt.figure(figsize=(8, 5))\n",
                "plt.pie(labels_count, labels=labels_name, autopct='%1.1f%%', colors=['#ff9999','#66b3ff','#99ff99'])\n",
                "plt.title('Training Data Distribution')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5ï¸âƒ£ ç¬¬äº”æ­¥ï¼šæ¨¡åž‹è®­ç»ƒ (Model Training)\n",
                "\n",
                "è¿™æ˜¯æœ€æ¿€åŠ¨äººå¿ƒçš„ä¸€æ­¥ï¼æˆ‘ä»¬å°†å¯åŠ¨ Hugging Face `Trainer`ã€‚\n",
                "\n",
                "æˆ‘ä»¬å°†å®žçŽ°ä¸€ä¸ª**â€œæ™ºèƒ½è·³è¿‡â€**é€»è¾‘ï¼šå¦‚æžœæ£€æµ‹åˆ°ä¹‹å‰å·²ç»è®­ç»ƒå¥½äº†æ¨¡åž‹ï¼Œå°±ç›´æŽ¥åŠ è½½ï¼Œä¸å†æµªè´¹æ—¶é—´é‡æ–°è®­ç»ƒã€‚"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# å®šä¹‰è¯„ä»·æŒ‡æ ‡ï¼šæˆ‘ä»¬éœ€è¦çŸ¥é“æ¨¡åž‹çš„å‡†ç¡®çŽ‡(Accuracy)\n",
                "def compute_metrics(pred):\n",
                "    labels = pred.label_ids\n",
                "    preds = pred.predictions.argmax(-1)\n",
                "    acc = accuracy_score(labels, preds)\n",
                "    return {'accuracy': acc}\n",
                "\n",
                "# æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨\n",
                "if os.path.exists(Config.OUTPUT_DIR) and os.path.exists(os.path.join(Config.OUTPUT_DIR, \"config.json\")):\n",
                "    print(f\"ðŸŽ‰ æ£€æµ‹åˆ°å·²è®­ç»ƒçš„æ¨¡åž‹: {Config.OUTPUT_DIR}\")\n",
                "    print(\"ðŸš€ ç›´æŽ¥åŠ è½½æ¨¡åž‹ï¼Œè·³è¿‡è®­ç»ƒï¼\")\n",
                "    model = AutoModelForSequenceClassification.from_pretrained(Config.OUTPUT_DIR)\n",
                "    model.to(device)\n",
                "else:\n",
                "    print(\"ðŸ’ª æœªæ‰¾åˆ°å·²è®­ç»ƒæ¨¡åž‹ï¼Œå¼€å§‹æ–°ä¸€è½®è®­ç»ƒ...\")\n",
                "    \n",
                "    # åŠ è½½åˆå§‹æ¨¡åž‹\n",
                "    model = AutoModelForSequenceClassification.from_pretrained(Config.BASE_MODEL, num_labels=Config.NUM_LABELS)\n",
                "    model.to(device)\n",
                "    \n",
                "    # è®¾ç½®è®­ç»ƒå‚æ•°\n",
                "    training_args = TrainingArguments(\n",
                "        output_dir=Config.OUTPUT_DIR,\n",
                "        num_train_epochs=Config.NUM_EPOCHS,\n",
                "        per_device_train_batch_size=Config.BATCH_SIZE,\n",
                "        evaluation_strategy=\"epoch\", # æ¯ä¸ª Epoch ç»“æŸåŽè¯„ä¼°ä¸€æ¬¡\n",
                "        save_strategy=\"epoch\",       # æ¯ä¸ª Epoch ç»“æŸåŽä¿å­˜ä¸€æ¬¡\n",
                "        logging_steps=10,\n",
                "        report_to=\"none\"             # ä¸ä¸ŠæŠ¥åˆ°wandb\n",
                "    )\n",
                "    \n",
                "    # åˆå§‹åŒ–è®­ç»ƒå™¨\n",
                "    trainer = Trainer(\n",
                "        model=model,\n",
                "        args=training_args,\n",
                "        train_dataset=dataset['train'],\n",
                "        eval_dataset=dataset['test'],\n",
                "        processing_class=tokenizer,\n",
                "        compute_metrics=compute_metrics\n",
                "    )\n",
                "    \n",
                "    # å¼€å§‹è®­ç»ƒï¼\n",
                "    trainer.train()\n",
                "    \n",
                "    # ä¿å­˜æœ€ç»ˆç»“æžœ\n",
                "    trainer.save_model(Config.OUTPUT_DIR)\n",
                "    tokenizer.save_pretrained(Config.OUTPUT_DIR)\n",
                "    print(\"ðŸ’¾ è®­ç»ƒå®Œæˆï¼Œæ¨¡åž‹å·²ä¿å­˜ï¼\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6ï¸âƒ£ ç¬¬å…­æ­¥ï¼šäº’åŠ¨æµ‹è¯• (Inference Demo)\n",
                "\n",
                "çŽ°åœ¨æ¨¡åž‹å·²ç»â€œæ¯•ä¸šâ€äº†ï¼Œè®©æˆ‘ä»¬æ¥è€ƒè€ƒå®ƒï¼\n",
                "åœ¨ä¸‹é¢çš„è¾“å…¥æ¡†é‡Œéšä¾¿è¾“å…¥ä¸€å¥è¯ï¼ˆæ”¯æŒä¸­æ–‡ï¼‰ï¼Œç‚¹å‡»â€œåˆ†æžâ€çœ‹çœ‹å®ƒè§‰å¾—çš„æƒ…æ„Ÿæ˜¯ä»€ä¹ˆã€‚"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import ipywidgets as widgets\n",
                "from IPython.display import display\n",
                "\n",
                "# é¢„æµ‹å‡½æ•°\n",
                "def predict_sentiment(text):\n",
                "    # 1. é¢„å¤„ç†\n",
                "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128, padding=True)\n",
                "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
                "    \n",
                "    # 2. æ¨¡åž‹æŽ¨ç†\n",
                "    with torch.no_grad():\n",
                "        outputs = model(**inputs)\n",
                "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
                "        \n",
                "    # 3. ç»“æžœè§£æž\n",
                "    pred_idx = torch.argmax(probs).item()\n",
                "    confidence = probs[0][pred_idx].item()\n",
                "    label = Config.ID2LABEL[pred_idx]\n",
                "    \n",
                "    return label, confidence\n",
                "\n",
                "# ç•Œé¢ç»„ä»¶\n",
                "text_box = widgets.Text(placeholder='è¯·è¾“å…¥è¦åˆ†æžçš„å¥å­...', description='è¯„è®º:', layout=widgets.Layout(width='400px'))\n",
                "btn_run = widgets.Button(description=\"å¼€å§‹åˆ†æž\", button_style='primary')\n",
                "output_area = widgets.Output()\n",
                "\n",
                "def on_click(b):\n",
                "    with output_area:\n",
                "        output_area.clear_output()\n",
                "        text = text_box.value\n",
                "        if not text:\n",
                "            print(\"âŒ è¯·å…ˆè¾“å…¥å†…å®¹ï¼\")\n",
                "            return\n",
                "        \n",
                "        print(f\"ðŸ” æ­£åœ¨åˆ†æž: \\\"{text}\\\"\")\n",
                "        label, conf = predict_sentiment(text)\n",
                "        \n",
                "        # åªæœ‰ç½®ä¿¡åº¦é«˜æ‰æ˜¾ç¤ºç»¿è‰²ï¼Œå¦åˆ™æ˜¾ç¤ºé»„è‰²\n",
                "        icon = \"âœ…\" if conf > 0.8 else \"ðŸ¤”\"\n",
                "        print(f\"{icon} é¢„æµ‹ç»“æžœ: [{label}] \")\n",
                "        print(f\"ðŸ“Š ç½®ä¿¡åº¦: {conf*100:.2f}%\")\n",
                "\n",
                "btn_run.on_click(on_click)\n",
                "display(text_box, btn_run, output_area)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}