{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ä¸­æ–‡æƒ…æ„Ÿåˆ†ææ¨¡å‹è®­ç»ƒæ•™ç¨‹ (Chinese Sentiment Analysis Tutorial)\n",
                "\n",
                "æ¬¢è¿æ¥åˆ°è¿™ä¸ªé€šè¿‡ **Hugging Face Transformers** å’Œ **BERT** è¿›è¡Œä¸­æ–‡æƒ…æ„Ÿåˆ†æçš„äº¤äº’å¼æ•™ç¨‹ï¼\n",
                "\n",
                "**æœ¬æ•™ç¨‹ä¸“ä¸ºå­¦ä¹ è®¾è®¡ï¼Œæ‰€æœ‰çš„æ ¸å¿ƒä»£ç éƒ½ç›´æ¥åŒ…å«åœ¨ä¸‹æ–¹çš„å•å…ƒæ ¼ä¸­ï¼Œæ— éœ€è·³è½¬æŸ¥çœ‹å¤–éƒ¨æ–‡ä»¶ã€‚**\n",
                "\n",
                "æˆ‘ä»¬å°†ä¸€èµ·å®Œæˆä»¥ä¸‹æ­¥éª¤ï¼š\n",
                "1. **ç¯å¢ƒæ£€æŸ¥**ï¼šç¡®è®¤ PyTorch å’Œ MPS (Mac åŠ é€Ÿ) æ˜¯å¦å¯ç”¨ã€‚\n",
                "2. **é…ç½® (Configuration)**ï¼šå®šä¹‰æ¨¡å‹å‚æ•°ã€è·¯å¾„å’Œè®­ç»ƒè®¾ç½®ã€‚\n",
                "3. **æ•°æ®é¢„å¤„ç†**ï¼šä» Hugging Face åŠ è½½æ•°æ®ï¼Œæ¸…æ´—å¹¶è¿›è¡Œ Tokenization (åˆ†è¯)ã€‚\n",
                "4. **æ•°æ®å¯è§†åŒ–**ï¼šç»˜åˆ¶æ•°æ®åˆ†å¸ƒå›¾ï¼Œäº†è§£æ­£è´Ÿæ ·æœ¬æ¯”ä¾‹ã€‚\n",
                "5. **æ¨¡å‹æ„å»ºä¸è®­ç»ƒ**ï¼šè‡ªåŠ¨æ£€æµ‹æ˜¯å¦å·²æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œå¦‚æœæœ‰åˆ™ç›´æ¥åŠ è½½ï¼Œæ— éœ€ç­‰å¾…ã€‚\n",
                "6. **è¯„ä¼°ä¸é¢„æµ‹**ï¼šæŸ¥çœ‹è®­ç»ƒæ›²çº¿ï¼ˆå¦‚æœåˆšè®­ç»ƒå®Œï¼‰å¹¶äº²æ‰‹è¿›è¡Œæµ‹è¯•ã€‚\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. å¯¼å…¥åº“ä¸ç¯å¢ƒæ£€æŸ¥\n",
                "æˆ‘ä»¬é¦–å…ˆå¯¼å…¥å¿…è¦çš„ Python åº“ï¼Œå¹¶æ£€æŸ¥æ‚¨çš„ Mac æ˜¯å¦æ”¯æŒç¡¬ä»¶åŠ é€Ÿã€‚"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "import json\n",
                "import torch\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import glob\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from datasets import load_dataset, concatenate_datasets\n",
                "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
                "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
                "\n",
                "# æ£€æŸ¥ Mac MPS åŠ é€Ÿ\n",
                "if torch.backends.mps.is_available():\n",
                "    device = torch.device(\"mps\")\n",
                "    print(\"âœ… æˆåŠŸå¼€å¯ Mac MPS (Metal Performance Shaders) ç¡¬ä»¶åŠ é€Ÿï¼\")\n",
                "else:\n",
                "    device = torch.device(\"cpu\")\n",
                "    print(\"âš ï¸ æœªæ£€æµ‹åˆ° MPSï¼Œå°†ä½¿ç”¨ CPU è®­ç»ƒ (é€Ÿåº¦è¾ƒæ…¢)ã€‚\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. å®šä¹‰é…ç½® (Config)\n",
                "æˆ‘ä»¬å°†æ‰€æœ‰çš„å‚æ•°éƒ½åœ¨è¿™é‡Œå®šä¹‰å¥½ï¼Œæ–¹ä¾¿é›†ä¸­ç®¡ç†ã€‚"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class Config:\n",
                "    # === æ¨¡å‹é…ç½® ===\n",
                "    BASE_MODEL = \"google-bert/bert-base-chinese\"\n",
                "    NUM_LABELS = 3\n",
                "    MAX_LENGTH = 128\n",
                "    \n",
                "    # === è·¯å¾„é…ç½® ===\n",
                "    # æˆ‘ä»¬æŠŠ Notebook è®­ç»ƒçš„æ¨¡å‹ä¿å­˜åœ¨è¿™é‡Œçš„ checkpoints æ–‡ä»¶å¤¹ä¸‹\n",
                "    OUTPUT_DIR = \"../checkpoints/tutorial_model\"\n",
                "    LOG_DIR = \"../results/notebook_logs\"\n",
                "    \n",
                "    # === è®­ç»ƒå‚æ•° ===\n",
                "    BATCH_SIZE = 32\n",
                "    LEARNING_RATE = 2e-5\n",
                "    NUM_EPOCHS = 3\n",
                "    \n",
                "    # === æ ‡ç­¾æ˜ å°„ ===\n",
                "    LABEL2ID = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
                "    ID2LABEL = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
                "    \n",
                "print(\"é…ç½®å·²åŠ è½½ã€‚\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. æ•°æ®å¤„ç† (Data Processor)\n",
                "åŠ è½½æ•°æ®ï¼Œæ¸…æ´—ï¼Œç»Ÿä¸€æ ¼å¼ã€‚"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class DataProcessor:\n",
                "    def __init__(self, tokenizer):\n",
                "        self.tokenizer = tokenizer\n",
                "\n",
                "    def clean_data(self, example):\n",
                "        text = example['text']\n",
                "        if text is None or \"æ­¤ç”¨æˆ·æœªå¡«å†™è¯„ä»·å†…å®¹\" in text or len(text.strip()) < 2:\n",
                "            return False\n",
                "        return True\n",
                "\n",
                "    def unify_labels(self, example):\n",
                "        label = example['label']\n",
                "        if isinstance(label, str):\n",
                "            label = label.lower()\n",
                "            if label in ['negative', 'pos', '0']: return {'label': 0}\n",
                "            elif label in ['neutral', 'neu', '1']: return {'label': 1}\n",
                "            elif label in ['positive', 'neg', '2']: return {'label': 2}\n",
                "        return {'label': int(label)}\n",
                "\n",
                "    def tokenize_function(self, examples):\n",
                "        return self.tokenizer(\n",
                "            examples['text'],\n",
                "            padding=\"max_length\",\n",
                "            truncation=True,\n",
                "            max_length=Config.MAX_LENGTH\n",
                "        )\n",
                "\n",
                "    def get_processed_dataset(self):\n",
                "        print(\"æ­£åœ¨åŠ è½½æ•°æ®é›†...\")\n",
                "        # ä½¿ç”¨æœ¬åœ° data ç›®å½•ç¼“å­˜\n",
                "        cache_dir = \"../data\"\n",
                "        ds_clap = load_dataset(\"clapAI/MultiLingualSentiment\", split=\"train[:3000]\", trust_remote_code=True, cache_dir=cache_dir)\n",
                "        ds_med = load_dataset(\"OpenModels/Chinese-Herbal-Medicine-Sentiment\", split=\"train[:3000]\", trust_remote_code=True, cache_dir=cache_dir)\n",
                "        \n",
                "        if 'review_text' in ds_med.column_names: ds_med = ds_med.rename_column('review_text', 'text')\n",
                "        if 'sentiment_label' in ds_med.column_names: ds_med = ds_med.rename_column('sentiment_label', 'label')\n",
                "        if 'language' in ds_clap.column_names: ds_clap = ds_clap.filter(lambda x: x['language'] == 'zh')\n",
                "            \n",
                "        common_cols = ['text', 'label']\n",
                "        combined = concatenate_datasets([ds_clap.select_columns(common_cols), ds_med.select_columns(common_cols)])\n",
                "        \n",
                "        combined = combined.filter(self.clean_data)\n",
                "        combined = combined.map(self.unify_labels)\n",
                "        \n",
                "        print(\"æ­£åœ¨åˆ†è¯...\")\n",
                "        tokenized_ds = combined.map(self.tokenize_function, batched=True)\n",
                "        return tokenized_ds.train_test_split(test_size=0.1)\n",
                "\n",
                "# åˆå§‹åŒ–\n",
                "tokenizer = AutoTokenizer.from_pretrained(Config.BASE_MODEL)\n",
                "dataset = None \n",
                "# æ³¨æ„ï¼šä¸ºäº†èŠ‚çœæ—¶é—´ï¼Œåªæœ‰åœ¨éœ€è¦è®­ç»ƒæ—¶æ‰åŠ è½½æ•°æ®\n",
                "print(\"Tokenizer å‡†å¤‡å°±ç»ªã€‚\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. æ™ºèƒ½è®­ç»ƒé€»è¾‘\n",
                "è¿™é‡Œæ˜¯æ ¸å¿ƒä¿®æ”¹ç‚¹ï¼š**å¦‚æœæ£€æµ‹åˆ°æ¨¡å‹å·²ç»å­˜åœ¨ï¼Œå°±ç›´æ¥è·³è¿‡è®­ç»ƒï¼Œç›´æ¥åŠ è½½ï¼**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# æ£€æŸ¥æ˜¯å¦å­˜åœ¨å·²ä¿å­˜çš„æ¨¡å‹\n",
                "model_path = Config.OUTPUT_DIR\n",
                "should_train = True\n",
                "\n",
                "if os.path.exists(model_path) and os.path.exists(os.path.join(model_path, \"config.json\")):\n",
                "    print(f\"âœ… æ£€æµ‹åˆ°å·²è®­ç»ƒçš„æ¨¡å‹ä½äº: {model_path}\")\n",
                "    print(\"ğŸš€ å°†è·³è¿‡è®­ç»ƒè¿‡ç¨‹ï¼Œç›´æ¥åŠ è½½è¯¥æ¨¡å‹ï¼\")\n",
                "    should_train = False\n",
                "    \n",
                "    # ç›´æ¥åŠ è½½å¾®è°ƒåçš„æ¨¡å‹\n",
                "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
                "    model.to(device)\n",
                "    \n",
                "else:\n",
                "    print(\"âš ï¸ æœªæ£€æµ‹åˆ°å·²å­˜åœ¨çš„æ¨¡å‹ï¼Œå‡†å¤‡å¼€å§‹è®­ç»ƒ...\")\n",
                "    \n",
                "    # 1. æ—¢ç„¶è¦è®­ç»ƒï¼Œé‚£æˆ‘ä»¬å°±éœ€è¦åŠ è½½æ•°æ®äº†\n",
                "    if dataset is None:\n",
                "        processor = DataProcessor(tokenizer)\n",
                "        dataset = processor.get_processed_dataset()\n",
                "        \n",
                "    # 2. åŠ è½½åŸºåº§æ¨¡å‹\n",
                "    model = AutoModelForSequenceClassification.from_pretrained(\n",
                "        Config.BASE_MODEL, \n",
                "        num_labels=Config.NUM_LABELS,\n",
                "        id2label=Config.ID2LABEL,\n",
                "        label2id=Config.LABEL2ID\n",
                "    )\n",
                "    model.to(device)\n",
                "\n",
                "    # 3. å®šä¹‰æŒ‡æ ‡\n",
                "    def compute_metrics(pred):\n",
                "        labels = pred.label_ids\n",
                "        preds = pred.predictions.argmax(-1)\n",
                "        precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
                "        acc = accuracy_score(labels, preds)\n",
                "        return {'accuracy': acc, 'f1': f1}\n",
                "\n",
                "    # 4. è®­ç»ƒå‚æ•°\n",
                "    training_args = TrainingArguments(\n",
                "        output_dir=Config.OUTPUT_DIR,\n",
                "        num_train_epochs=Config.NUM_EPOCHS,\n",
                "        per_device_train_batch_size=16,\n",
                "        logging_dir=Config.LOG_DIR,\n",
                "        logging_steps=10,\n",
                "        eval_strategy=\"steps\",\n",
                "        eval_steps=100,\n",
                "        save_steps=100,\n",
                "        save_total_limit=2,\n",
                "    )\n",
                "\n",
                "    # 5. Trainer\n",
                "    trainer = Trainer(\n",
                "        model=model,\n",
                "        args=training_args,\n",
                "        train_dataset=dataset['train'],\n",
                "        eval_dataset=dataset['test'],\n",
                "        processing_class=tokenizer,\n",
                "        compute_metrics=compute_metrics,\n",
                "    )\n",
                "\n",
                "    # 6. å¼€å§‹è®­ç»ƒ\n",
                "    print(\"å¼€å§‹è®­ç»ƒ...\")\n",
                "    trainer.train()\n",
                "    \n",
                "    # 7. ä¿å­˜\n",
                "    print(f\"ä¿å­˜æ¨¡å‹åˆ°: {Config.OUTPUT_DIR}\")\n",
                "    trainer.save_model(Config.OUTPUT_DIR)\n",
                "    tokenizer.save_pretrained(Config.OUTPUT_DIR)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. æ¨¡å‹æ¨ç† (Interactive Inference)\n",
                "æ— è®ºä½ æ˜¯åˆšè®­ç»ƒå®Œï¼Œè¿˜æ˜¯ç›´æ¥åŠ è½½çš„æ¨¡å‹ï¼Œéƒ½å¯ä»¥ç›´æ¥ç”¨ä¸‹é¢çš„ä»£ç æ¥æµ‹è¯•ï¼"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import ipywidgets as widgets\n",
                "from IPython.display import display\n",
                "\n",
                "def predict(text):\n",
                "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128, padding=True)\n",
                "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
                "    with torch.no_grad():\n",
                "        logits = model(**inputs).logits\n",
                "        probs = torch.nn.functional.softmax(logits, dim=-1)\n",
                "        pred_idx = torch.argmax(probs).item()\n",
                "        return Config.ID2LABEL[pred_idx], probs[0][pred_idx].item()\n",
                "\n",
                "text_input = widgets.Text(placeholder='è¾“å…¥ä¸­æ–‡...', description='è¯„è®º:')\n",
                "btn = widgets.Button(description=\"åˆ†æ\", button_style='info')\n",
                "out = widgets.Output()\n",
                "\n",
                "def on_click(b):\n",
                "    with out:\n",
                "        out.clear_output()\n",
                "        if not text_input.value: return\n",
                "        label, conf = predict(text_input.value)\n",
                "        print(f\"ç»“æœ: {label} (ç½®ä¿¡åº¦: {conf:.4f})\")\n",
                "\n",
                "btn.on_click(on_click)\n",
                "display(text_input, btn, out)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}